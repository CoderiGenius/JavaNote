## AtomicInteger
- 原子类相比于普通的锁，粒度更细、效率更高(除了高度竞争的情况下)
- 阻塞同步和非阻塞同步都是实现线程安全的两个保障手段
- 非阻塞同步对于阻塞同步而言主要解决了阻塞同步中线程阻塞和唤醒带来的性能问题
### 阻塞同步（悲观锁）
- synchronized关键字和可重入锁ReentrantLock是两种最为常用的互斥同步手段。
#### synchronized
- 经过编译之后会在同步块前后分别形成monitorenter和monitorexit这两个字解码命令
- 这两个命令都想需要一个reference类型的参数来指明要锁和解锁的对象
  - 如果synchronized明确指定了对象参数，那么就是这个对象的reference，
  - 如果没有指定，那么根据synchronized修饰的是实例方法还是类方法去取对应的对象实例或Class对象来作为锁对象。
- 在执行monitorenter命令时，首先尝试获取对象的锁，如果成功获取，就把锁的计数器加一；
- 相应的，执行monitorexit会将锁的计数器减一。如果获取对象失败，该线程就进入阻塞状态，直到对象锁被另一个线程释放为止。

- 注意一些情况：
  - synchronized同步块对同一线程来说是可重入的，不会出现自己把自己锁死的问题；
  - 同步块在已进入线程执行完之前，会阻塞后面线程的进入；
  - Java线程是映射到操作系统的原生线程上的，如果要阻塞和唤醒一个线程，都要操作系统来完成，这需要从用户态转到核心态，会消耗很多处理器时间，因此synchronized是一个重量级的操作。
#### 可重入锁ReentrantLock：
- 在用法上，ReentrantLock和synchronized很相似都具备一样的线程重入特性，但前者表现为API层面的互斥锁，后则表现为原生语法层面的互斥锁。不过，ReentrantLock比synchronized增加了一些高级功能：

- **等待可中断**：是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以放弃等待去做其他事情。
- **公平锁**：是指多个线程在等待同一个锁时，必须按照申请锁的顺序来依次获得锁。synchronized中的锁是非公平的，ReentrantLock默认也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。
- **锁绑定多个条件**：是指一个ReentrantLock对象可以同时绑定多个Condition对象，只需多次调用newCondition()方法即可。
- 若要使用上面的三种功能，ReentrantLock是很好的选择。但一般情况下使用synchronized就可以了。JDK1.5之前多线程环境下ReentrantLock要比synchronized效率高，然而JDK1.6引入锁优化之后，两者效率已经很接近。
### 非阻塞同步(乐观锁)
- 什么叫做非阻塞同步呢？
    - 在并发环境下，某个线程对共享变量先进行操作
    - 如果没有其他线程争用共享数据那操作就成功；
    - 如果存在数据的争用冲突，那就才去补偿措施，比如不断的重试机制，直到成功为止
    - 因为这种乐观的并发策略不需要把线程挂起，也就把这种同步操作称为非阻塞同步
    - （操作和冲突检测具备原子性）
### CAS指令（Compare-And-Swap比较并交换）
![](https://img-blog.csdnimg.cn/20190111101332407.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ZhbnJlbnhpYW5n,size_16,color_FFFFFF,t_70)
### 再返回来看AtomicInteger.incrementAndGet()方法
```
/**
     * Atomically increments by one the current value.
     *
     * @return the updated value
     */
    public final int incrementAndGet() {
        for (;;) {
            int current = get();
            int next = current + 1;
            if (compareAndSet(current, next))
                return next;
        }
    }

```
incrementAndGet()方法在一个无限循环体内，不断尝试将一个比当前值大1的新值赋给自己，如果失败则说明在执行"获取-设置"操作的时已经被其它线程修改过了，于是便再次进入循环下一次操作，直到成功为止。这个便是AtomicInteger原子性的"诀窍"了
#### 再往下看它的compareAndSet方法:
```
/**
    * Atomically sets the value to the given updated value
    * if the current value {@code ==} the expected value.
    *
    * @param expect the expected value
    * @param update the new value
    * @return true if successful. False return indicates that
    * the actual value was not equal to the expected value.
    */
   public final boolean compareAndSet(int expect, int update) {
       return unsafe.compareAndSwapInt(this, valueOffset, expect, update);
   }

```
可以看到，compareAndSet()调用的就是Unsafe.compareAndSwapInt()方法，即Unsafe类的CAS操作

## 锁优化：
#### 自旋锁与自适应自旋：
- 因为线程阻塞和唤醒要消耗大量处理器时间，所以在一些情况下，可以让要等待的线程“稍等一下”，但不放弃处理器，看看持有锁的线程是否会马上释放锁。为了让线程占有处理器等待，只需让线程执行一个忙循环（自旋），这就是自旋锁。

- 自旋锁不能代替阻塞，因为它是占用处理器时间的，如果锁被占用的时间很短，自旋锁效果会很好，但如果锁被占用时间很长，那自旋线程就会白白消耗处理器资源。所以自旋锁一般会指定自选次数，默认10次。

- **自适应自旋锁** 是自选时间时间不固定，而是由前一次在同一个锁上的自旋线程的自旋时间以及锁的拥有者状态来决定。如果前一次的自旋线程刚刚成功获得锁，那么虚拟机认为这次也会容易获得锁，进而允许自旋线程多自旋几次比如100次；而如果对于某个锁自旋很少成功过，那么以后的线程可能直接忽略掉自旋过程。
#### 锁清除：
- 锁清除是指虚拟机即时编译器在运行时，会将代码上要求同步，但被检测到实际上不可能出现共享数据竞争的锁进行清除。锁清除的主要判定依据来源于逃逸分析的数据支持。

#### 锁粗化：
很多情况下，总是推荐将同步代码块的范围限制得越小越好。但在一些情况下，如果一系列连续操作都对同一个对象反复加锁和解锁，甚至加锁解锁关系出现在循环体中，那么也会消耗性能。如果虚拟机探测到有这样的操作，就会把加锁同步的范围扩展（粗化）到整个操作序列之外。

#### 轻量级锁：
“轻量级”是相对于使用系统互斥量实现的传统锁而言的，因此传统的锁机制就是重量级锁。强调一点是：轻量级锁不是为了取代重量级锁的，而是在没有多线程竞争的前提下，减少传统重量级锁使用操作系统互斥量产生的性能消耗。

轻量级锁提升系统同步性能的依据是“对于绝大多数锁，在整个同步周期内是不存在竞争的”，这是一个经验数据。但如果存在竞争，除了传统锁互斥量的开销外，还额外发生了CAS操作，因此会更慢。

#### 偏向锁：
如果说轻量级锁是在无竞争的情况下使用CAS操作消除同步使用的互斥量，那么偏向锁就是在无竞争的情况下把整个同步都消除掉。偏向锁的意思是这个锁会偏向于第一个获取它的线程，如果在接下来的执行过程中，该锁没有被其他线程获取，则持有偏向锁的线程将永远不需要再进行同步。当有另一个线程去尝试获取这个锁时，偏向模式结束。
## volatile
- volatile 是一个类型修饰符。volatile 的作用是作为指令关键字，确保本条指令不会因编译器的优化而省略。
- volatile 的特性
  - 保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的。（实现可见性）
  - 禁止进行指令重排序。（实现有序性）
  - volatile 只能保证对单次读/写的原子性。i++ 这种操作不能保证原子性。
- 可见性实现：
  - volatile 变量的内存可见性是基于内存屏障（Memory Barrier）实现。
  - 内存屏障，又称内存栅栏，是一个 CPU 指令。
  - 在程序运行时，为了提高执行性能，编译器和处理器会对指令进行重排序，JMM 为了保证在不同的编译器和 CPU 上有相同的结果，通过插入特定类型的内存屏障来禁止特定类型的编译器重排序和处理器重排序，插入一条内存屏障会告诉编译器和 CPU：**不管什么指令都不能和这条 Memory Barrier 指令重排序。**
  - 声明了volatitle的操作前面会加lock，lock 前缀的指令在多核处理器下会引发两件事情
    - 将当前处理器缓存行的数据写回到系统内存。
    - 写回内存的操作会使在其他 CPU 里缓存了该内存地址的额数据无效。
  - 为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1，L2 或其他）后再进行操作，但操作完不知道何时会写到内存。
  - 如果对声明了 volatile 的变量进行写操作，JVM 就会向处理器发送一条 lock 前缀的指令，将这个变量所在缓存行的数据写回到系统内存。
  - 为了保证各个处理器的缓存是一致的，实现了缓存一致性协议（MESI），每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把数据读到处理器缓存里。
  - 所有多核处理器下还会完成：3）当处理器发现本地缓存失效后，就会从内存中重读该变量数据，即可以获取当前最新值
- volatile 有序性实现
  - volatile 的 happens-before 关系
  - happens-before 规则中有一条是 volatile 变量规则：对一个 volatile 域的写，happens-before 于任意后续对这个 volatile 域的读。
  - 即，立即生效
### volatile 的应用场景
- 适合一个线程写 多个线程读的场景 其他场景都要用锁
- 使用 volatile 必须具备的条件

  - 对变量的写操作不依赖于当前值。
  - （？？？？）该变量没有包含在具有其他变量的不变式中。
- 只有在状态真正独立于程序内其他内容时才能使用 volatile。

## 非阻塞算法 lock-free 和wait-free
- lock-free和wait-free算法是指对于共享的数据并非对其加锁来控制访问，而是多个线程并行的访问。通过该算法可以达到对共享对象并发的读写而不会破坏对象本身。
### lock-free
- 所谓lock-free是指对于线程不加锁，让系统执行所有的步骤。lock-free提到的不加锁是指不使用类似于互斥锁或者信号量之类的排他机制。因为一旦对线程加锁的话，当线程执行中断时，那么对于这个系统来说运行也中断了。
### wait-free
- 是指，不管其他线程执行什么操作，线程无论有什么操作都能在有限的步骤里面完成。所以对于算法来说达到lock-free不一定能达到wait-free，但是达到wait-free的算法一定是lock-free的。

### 意义
- 在多线程编程中，对于共享资源的访问最传统的做法就是加锁。
- 互斥锁和信号量本质上都是在代码层面的某一段逻辑上加上排他机制，从而达到对于共享资源的访问不造成破坏性的结果。假如某个线程需要获得已经被其他线程先占有的锁，那么在那个锁释放之前，这个线程的工作会陷入停止状态。
- 很多情况下，我们都不希望看到线程的运行停止。首先，阻塞中的线程无法做任何事情。其次，如果线程要处理的事务优先级很高乃至要实时处理的话，我们也不希望看到线程被阻塞。再者，当多个资源被锁的时候，就容易出现死锁、活锁或者优先顺序颠倒等问题。最后，使用锁的地方，如果对加锁的逻辑颗粒度很大的话会导致并行处理的机会会减少，如果加锁颗粒度太细又容易产生bug而不得不小心设计，最后陷入死胡同。
### wait-free的数据结构
使用wait-free的数据结构的应用程序中，与其将原来使用互斥的算法改造为wait-free的算法，不如直接使用基于wait-free算法开发的stack、queue、set和map。例如，在Java 5以后，java.util.concurrent包中就引入了wait-free的数据结构。通过直接使用这些wait-free的数据结构，编写线程的异步数据访问也将变得很容易。
### 举个银行存钱的例子
例如，在银行的柜台有个存钱的程序。每个线程相当于一个ATM。当金钱存入的时候，需要将当前余额读出来，然后加上要存入的金额算出新的余额。如果通过锁来实现的话，当一台ATM在计算的时候，为了让其他ATM不能同时变更余额，需要加锁。否则的话，如果同时更新将导致数据错误。如果通过lock-free来实现的话，需要一个管理所有存入请求的独立线程，然后创建一个wait-free的队列。所有ATM异步的将存入金额的请求放入队列中而无需加任何的锁。管理所有存入请求的独立线程从队列中依次取出请求，更新账户余额。通过以上方式，无需单独实现lock-free的存钱算法，编程也更加便捷。同时，该方法因为队列是wait-free的，所以不仅仅实现了lock-free也实现了wait-free。对于余额的更新如果需要N并发的话，只需要创建N个wait-free的队列，然后根据账号对N取余放入对应队列中即可
### CAS Compare and Swap
在实现lock-free和wait-free算法时，需要CPU专用的管理指令来完成。其中最重要的就是Compare and Swap（简称CAS）。在Java中，在java.util.concurrent.atomic包中类方法compareAndSet来实现。其中使用到了内存地址、旧值和新值。如果该地址所保存的值和旧值相同则替换为新值，如果不是的话则什么都不做。然后将处理成功与否的结果返回。所以需要CPU支持该方法。目前Intel的芯片中有该功能。通过该功能实现了从内存中读出数据，进行更新后写入的时候其他线程无法同时更新的算法。
继续拿前面的银行柜台来举例，我们换个算法来实现。ATM将当前余额读出、计算再写入这三个步骤可以类比为CPU的CAP操作。进行这三个步骤的时候，没有其他线程更新该值的话则认为操作成功。如果在进行这三步的时候，第一步读出的金额和第三步更新要用新值去替换的金额不一致的情况下，命令直接失败，然后操作回滚到第一步重新执行。所有的ATM都是遵循这个方法，在成功之前都反复执行这三步。这个算法是lock-free的但是不是wait-free的。因为当其他ATM进行操作的时候，会影响当前ATM的操作，导致可能要反复执行步骤。
